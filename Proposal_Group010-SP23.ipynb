{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Jason Liang\n",
    "- Tasnia Jamal\n",
    "- Thanh Derek Nguyen\n",
    "- Wilson Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Credit scores are values that assist financial institutions in making decisions regarding the granting of credit. The credit standing for individuals is typically based on a multitude of factors and requires nuanced computational methods to ensure accurate predictions, especially in a turbulent market when bestowers need to seriously consider whether a person is worthy of loans. The goal of this research project is to predict credit card standing for individuals based on a variety of variables like annual income, monthly base salary, occupation, and other personal financial statistics. Our workflow consists of cleaning the data and normalizing it, and then used to build supervised machine learning models like linear regression, logistic regression, decision trees, and K-nearest neighbors and then using obtained performance and error metrics, conclude which model is best for classifying a person's credit score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In finances, credit scoring is a way of analyzing statistical data used in financial organizations and banks to acquire a person's credit worthiness. The score itself plays a significant role in determining the credit worthiness of a person and if they are qualified to sanction a loan from the bank. The process of credit scoring is normally automated using machine learning techniques and involves evaluating various factors related to a person's or entity's credit history and financial behavior to determine the likelihood of repaying debts and fulfilling financial obligations <a name=\"abdou\"></a>[<sup>[1]</sup>](#Abdou). \n",
    "\n",
    "The primary purpose of credit scoring is to help lenders make informed decisions about extending credit to potential borrowers, allowing them to evaluate the risk associated with lending money to an individual or business. This allows them to determine the terms and conditions of the pending credit offer, including interest rates and credit limits. In common credit scoring models, the following are some of the main criteria used when calculating a score:\n",
    "\n",
    "1. Payment history: This factor assesses the borrower's track record of making payments on time, including any late or missed payments.\n",
    "2. Credit utilization: This measures the amount of credit a borrower is using in relation to their available credit limits. Higher credit limit may negatively impact overall credit score.\n",
    "3. Length of credit history: The length of time the borrower has been using credit is taken into account. A longer credit history is typically viewed positively.\n",
    "4. Credit mix: This factor considers the borrower's mix of credit accounts, such as credit cards mortgages, and loans. Having a diverse credit mix may be seen as positive.\n",
    "5. New credit applications: Recent applications for credit or loans may have an impact on the credit score, as multiple applications within a short period can be viewed as a sign of financial instability <a name=\"xiao\"></a>[<sup>[2]</sup>](#Xiao).\n",
    "\n",
    "The model then assigns a numerical value to each factor and generates a score (typically via machine learning models) that ranges from a minimum to a maximum value. The most commonly used scoring system is the FICO score, devloped by the Fair Isaac Corporation <a name=\"fico\"></a>[<sup>[3]</sup>](#FICO). It ranges from 300 to 850, with higher scores indicating lower credit risk. With the recent failure of Silicon Valley Bank and the decline of major tech giants in what appears to a recession, it is more important than ever to develop accurate computational models that assist financial institutions in the decision-making process at the time of a customer's financial request. Today, the credit market demands new tools and technologies that can contribute to this classification.\n",
    "\n",
    "In our research, we attempt to apply machine learning techniques to credit analysis, specifically in predicting a person's credit score and in doing so, evaluating which variables are most relevant in defining good and bad payers. The main question at hand here is how do we measure the risk in granting credit to inviduals with greater accuracy <a name=\"pincovsky\"></a>[<sup>[4]</sup>](#Pincovsky)? Some of the secondary points to consider that will aid us in answering include determining the variables that defines the individual's ability to pay, what makes an individual take credit even though they are aware they don't have the resources to pay, and how does the individual's behavior as a consumer impact their own credit score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem involves creating a machine learning model to try and predict a persons credit score by using different variables. In order to create this model to solve this problem, we need to take into account a range of relevant parameters such as income, age, and employment status. This problem is quantifiable because it involves assigning numerical values to a persons credit standing. For example, we can use a number range of 300 to 850 and create thresholds to indicate what will be considered as \"Poor,\" \"Fair,\" \"Good,\" or \"Excellent.\" The problem is measurable because credit score has had a long running background of its form of operation. After comparing the predicted credit scores to the true credit scores, we can then evaluate the accuracy and efficiency of the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "In the credit card dataset from Kaggle<a name=\"kaggledata\"></a>[<sup>[5]</sup>](#kaggle), it contains more than 10,000 observations with 27 different variables, including the following relevant ones:\n",
    "\n",
    "Month\n",
    "\n",
    "Name\n",
    "\n",
    "Age\n",
    "\n",
    "SSN\n",
    "\n",
    "Occupation\n",
    "\n",
    "Annual_Income\n",
    "\n",
    "Monthly_Inhand_Salary\n",
    "\n",
    "Num_Bank_Accounts\n",
    "\n",
    "Num_Credit_Card\n",
    "\n",
    "Interest_Rate\n",
    "\n",
    "Num_of_Loan\n",
    "\n",
    "Type_of_Loan\n",
    "\n",
    "Delay_from_due_date\n",
    "\n",
    "Num_of_Delayed_Payment\n",
    "\n",
    "Changed_Credit_Limit\n",
    "\n",
    "Num_Credit_Inquiries\n",
    "\n",
    "Credit_Mix\n",
    "\n",
    "Outstanding_Debt\n",
    "\n",
    "Credit_Utilization_Ratio\n",
    "\n",
    "Credit_History_Age\n",
    "\n",
    "Payment_of_Min_Amount\n",
    "\n",
    "Total_EMI_per_month\n",
    "\n",
    "Amount_invested_monthly\n",
    "\n",
    "Payment_Behaviour\n",
    "\n",
    "Monthly_Balance\n",
    "\n",
    "We plan on fitting multiple models and seeing which one performs best on this dataset after performing EDA. What we know is that the dataset is balanced as described but some observations contain missing values so we will definitely clean/take that into account. Since our model relies on accuracy and we believe several factors are taken into credit score prediction, it is likely we will train our data using several of these variables. However, we do have to consider the dangers of the curse of dimensionality if we choose to implement K-nearest neighbors. We want to observe how the factors previously mention correlate with credit standing and use that to make further predictions for new metadata. We plan to clean up this data because there are many samples with blanks and do further preprocessing in the event we need to one-hot encode some of the categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To accurately carry out our experiment we will employ a comparative analysis methodology. The goal is to load the respective dataset and preprocess it and then apply various classification algorithms to the dataset. We will then evaluate the derived models subject to performance metrics and error measures and find out the best model with high accuracy and low error rate in base and ensemble algorithms using the concepts discussed in lecture. \n",
    "\n",
    "As described in the data section, we may use our EDA to make informed decisions about what variables to select for training the model. For instance, we might graph or cluster some of the data to see at first glance what kind of data we are dealing with and if there already exists any apparent relationships between any of the variables. Then, for some of the base classifiers, we will use techniques like logistic regression, linear regression, decision trees, and the K-nearest neighbors algorithm. For the ensemble classifiers, we will use techniques like random forests. \n",
    "\n",
    "The general surrogate credit classification modeling workflow at a high-level is presented as follows. We select data set inputs $X$ and label the outputs $Y$. Note that the dataset has already been split into training and validation data before this. Then for each new algorithm, we then use $(X, Y)$ to train and estimate a black box model $M$. Then using the model $M$, we obtain in-sample predicted values of $Y, \\hat{Y}$ and then use $(X, \\hat{Y})$ to train and estimate an interpretable $N$ on the unseen dataset. Finally, we compare the models generated using several metrics. These include accuracy, precision, recall, and F1-score for our performance metrics and mean absolute error and root mean squared error for our error metrics. We prioritize accuracy and F1-score, since we do not want to overestimate the trustworthiness of a person nor do we want to discredit a person's ability to pay; we want a balance between the two.\n",
    "\n",
    "For many of the models mentioned above, we will use Python libraries like Sci-kit Learn, PyTorch, Numpy, and Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will be evaluating the accuracy of our methods by seeing how well it does on classifying unseen data. Depending on the selected model, we will be using include accuracy, precision, recall, and F1-score for our performance metrics and mean absolute error and root mean squared error for our error metrics. We prioritize accuracy and F1-score as previously mentioned. Our methods for selecting the best model will be based on the methods described in the lecture by looking at our generated metrics as mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our project focuses on credit card classification, several ethical and privacy concerns must be considered. First, we must consider data privacy and security since credit card data is confidential and highly sensitive. We plan to address concern issue by implementing encryption techniques and strong data security measures that will ensure privacy and prevent unauthorized access. Another concern is the biases that may emerge from an imbalance in our data collection or biased decision-making during the data labeling process. We plan to address this concern by building models that are fair and unbiased, while actively working to identify and mitigate any unfair impacts. Lastly, we might face concerns regarding transparency so we plan to make sure sure that the models used for classification to be transparent and explainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1: Be transparent about our schedules*\n",
    "* *Team Expectation 2: We will do our best to evenly spread out the work*\n",
    "* *Team Expecation 3: Similarly (to 1), we will communicate difficulties in topics or parts of the project. If we are going to need extra time or help, we will reach out to our partners or TAs.*\n",
    "* *Team Expectation 4: We will do our best to attend all group meetings and meet 2 days before each mildstone.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 5/16  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss potential final project topics; discuss hypothesis| \n",
    "| 5/17  |  5 PM |  Decide topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 5/17  | 7 PM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/21  | 6 PM  | Import & Wrangle Data ,do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/24  | 12 PM  | Finalize wrangling/EDA; Begin programming for project | Discuss/edit project code; Complete project |\n",
    "| 5/28  | 12 PM  | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 6/9  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"abdou\"></a>1.[^](#Abdou): Abdou, HAH and Pointon, J. (2011). Credit scoring, statistical\n",
    "techniques and evaluation criteria: A review of the literature, Intelligent Systems in Accounting, Finance Management. 18 (2-3), pp. 59-88.<br>\n",
    "<a name=\"xiao\"></a>2.[^](#Xiao): XIAO.-L. Li and Y. Zhong. (2012). An overview of personal credit scoring: Techniques and future work, ‖ International Journal of Intelligence Science, vol. 2, no. 4, pp. 181–189.<br>\n",
    "<a name=\"fico\"></a>3.[^](#FICO): https://www.fico.com/en/products/fico-score.<br>\n",
    "<a name=\"pincovsky\"></a>4.[^](#Pincovsky): M. Pincovsky, A. Falcão, W. N. Nunes, A. Paula Furtado and R. C. L. V. Cunha, \"\"Machine Learning applied to credit analysis: a Systematic Literature Review\",\" 2021 16th Iberian Conference on Information Systems and Technologies (CISTI), Chaves, Portugal, 2021, pp. 1-5, doi: 10.23919/CISTI52073.2021.9476350.<br>\n",
    "<a name=\"kaggledata\"></a>5.[^](#kaggle): https://www.kaggle.com/datasets/parisrohan/credit-score-classificationl<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
